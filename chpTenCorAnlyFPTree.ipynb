{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上一篇笔记我们讲到了关联分析的基本概念和应用场景，以及挖掘数据集中关联规则的**Apriori算法**，通过具体代码实现了一个Apriori算法，在上一篇笔记的最后提到Apriori算法的效率并不高，因此本章就深入一个优化了的关联规则算法FP-growth。\n",
    "\n",
    "\n",
    "FP-growth算法是伊利罗伊香槟分校的韩嘉炜教授于2004年[1]提出的，它是为了解决Apriori算法每次增加频繁项集的大小都要遍历整个数据库的缺点，特别是当数据集很大时，该算法执行速度要快于Apriori算法两个数量级。FP-growth算法的任务是将数据集存储在一个特定的称为FP树的结构之后发现频繁项集或者频繁项对，虽然它能够高效地发现频繁项集，但是不能用来发现关联规则，也就是只优化了Apriori算法两个功能中的前一个功能。\n",
    "\n",
    "\n",
    "FP-growth算法将数据存储在一个称为FP树的紧凑数据结构中，它与计算机科学中的其他树的结构类似，但是它通过链接来链接相似元素，被连起来的元素可以看做一个链表。\n",
    "\n",
    "![包含相似节点链接的FP树](./dsIpynbPic/FP_Tree_chpten.png)\n",
    "\n",
    "\n",
    "  FP-growth算法只需要对数据集进行两次扫描，所以即使数据集很大时也不会花费太多的时间在扫描数据上，它发现频繁项集的基本过程如下：\n",
    "    1）构建FP树\n",
    "    2）从FP树中挖掘频繁项集\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 创建FP Tree的数据结构\n",
    "\n",
    "对每一频繁项，都要创建一颗条件FP树，将上面的条件模式基作为输入，通过相同的建树方法来构建这些条件树，然后递归地发现频繁项、发现条件模式基，以及发现另外的条件树。举个例子，假定为频繁项t创建一个条件FP树，然后对{t,y}，{t,x}、...重复该过程。\n",
    "\n",
    "构建相关类的代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class treeNode:  #FP Tree的树节点\n",
    "    def __init__(self, nameValue, numOccur, parentNode):\n",
    "        self.name = nameValue\n",
    "        self.count = numOccur  #计数\n",
    "        self.parent = parentNode     #父节点\n",
    "        self.nodeLink = None  #横向链\n",
    "        self.children = {}   #子节点\n",
    "    \n",
    "    def inc(self, numOccur):\n",
    "        self.count += numOccur\n",
    "        \n",
    "    def disp(self, ind=1): #将树以文本形式显示\n",
    "        print ('  '*ind, self.name, ' ', self.count)\n",
    "        for child in self.children.values():\n",
    "            child.disp(ind+1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建 FP 树的函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createTree(dataSet, minSup=1): #从数据集创建FP Tree\n",
    "    headerTable = {}\n",
    "    #两次遍历数据集\n",
    "    for trans in dataSet:#第一次遍历：统计每个元素项出现次数\n",
    "        for item in trans:\n",
    "            headerTable[item] = headerTable.get(item, 0) + dataSet[trans]\n",
    "    klst=[j for j in  headerTable.keys()]\n",
    "    for k in klst:  #移除不满足最小支持度的元素项\n",
    "        if headerTable[k] < minSup: \n",
    "            del(headerTable[k])\n",
    "    freqItemSet = set(headerTable.keys())\n",
    "    if len(freqItemSet) == 0: return None, None  #i如果没有元素项满足要求，退出\n",
    "    for k in headerTable:\n",
    "        headerTable[k] = [headerTable[k], None] \n",
    "    retTree = treeNode('Null Set', 1, None) #建立树的节点\n",
    "    for tranSet, count in dataSet.items():  \n",
    "        localD = {}\n",
    "        for item in tranSet:  \n",
    "            if item in freqItemSet:\n",
    "                localD[item] = headerTable[item][0]\n",
    "        if len(localD) > 0: #对剩下的元素项迭代，调用updateTree\n",
    "            orderedItems = [v[0] for v in sorted(localD.items(), key=lambda p: p[1], reverse=True)]\n",
    "            updateTree(orderedItems, retTree, headerTable, count)\n",
    "    return retTree, headerTable \n",
    "\n",
    "def updateTree(items, inTree, headerTable, count): #增长更新树\n",
    "    if items[0] in inTree.children:\n",
    "        inTree.children[items[0]].inc(count) \n",
    "    else: #加入i[0]\n",
    "        inTree.children[items[0]] = treeNode(items[0], count, inTree)\n",
    "        if headerTable[items[0]][1] == None:\n",
    "            headerTable[items[0]][1] = inTree.children[items[0]]\n",
    "        else:\n",
    "            updateHeader(headerTable[items[0]][1], inTree.children[items[0]])\n",
    "    if len(items) > 1:\n",
    "        updateTree(items[1::], inTree.children[items[0]], headerTable, count)\n",
    "        \n",
    "def updateHeader(nodeToTest, targetNode):  \n",
    "    while (nodeToTest.nodeLink != None):   \n",
    "        nodeToTest = nodeToTest.nodeLink\n",
    "    nodeToTest.nodeLink = targetNode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**抽取条件模式基**(conditional pattern base)以及递归查找频繁项集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#发现以给定元素项结尾的所有路径\n",
    "def ascendTree(leafNode, prefixPath): #迭代上溯整棵树\n",
    "    if leafNode.parent != None:\n",
    "        prefixPath.append(leafNode.name)\n",
    "        ascendTree(leafNode.parent, prefixPath)\n",
    "    \n",
    "def findPrefixPath(basePat, treeNode): \n",
    "    #返回basePat对于的所有前缀和计数,treeNode是其对应的第一个节点\n",
    "    condPats = {}\n",
    "    while treeNode != None:\n",
    "        prefixPath = []\n",
    "        ascendTree(treeNode, prefixPath)\n",
    "        if len(prefixPath) > 1: \n",
    "            condPats[frozenset(prefixPath[1:])] = treeNode.count\n",
    "        treeNode = treeNode.nodeLink\n",
    "    return condPats\n",
    "\n",
    "def mineTree(inTree, headerTable, minSup, preFix, freqItemList): #递归查找频繁项集的函数\n",
    "    bigL = [v[0] for v in sorted(headerTable.items(), key=lambda p: p[1][0])]#排序头指针\n",
    "    for basePat in bigL:  #从头指针表的底端开始\n",
    "        newFreqSet = preFix.copy()\n",
    "        newFreqSet.add(basePat)\n",
    "        \n",
    "        freqItemList.append(newFreqSet)\n",
    "        condPattBases = findPrefixPath(basePat, headerTable[basePat][1])\n",
    "        #从条件模式基构建FP树\n",
    "        myCondTree, myHead = createTree(condPattBases, minSup)\n",
    "        \n",
    "        if myHead != None: #挖掘条件FP树\n",
    "            mineTree(myCondTree, myHead, minSup, newFreqSet, freqItemList)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建一个虚拟的数据集进行测试："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Null Set   1\n",
      "     z   5\n",
      "       r   1\n",
      "       x   3\n",
      "         y   3\n",
      "           s   2\n",
      "             t   2\n",
      "           r   1\n",
      "             t   1\n",
      "     x   1\n",
      "       s   1\n",
      "         r   1\n"
     ]
    }
   ],
   "source": [
    "def createInitSet(dataSet):\n",
    "    retDict = {}\n",
    "    for trans in dataSet:\n",
    "        retDict[frozenset(trans)] = 1\n",
    "    return retDict\n",
    "\n",
    "#测试数据\n",
    "simpDat = [['r', 'z', 'h', 'j', 'p'],\n",
    "               ['z', 'y', 'x', 'w', 'v', 'u', 't', 's'],\n",
    "               ['z'],\n",
    "               ['r', 'x', 'n', 'o', 's'],\n",
    "               ['y', 'r', 'x', 'z', 'q', 't', 'p'],\n",
    "               ['y', 'z', 'x', 'e', 'q', 's', 't', 'm']]\n",
    "\n",
    "#调用\n",
    "\n",
    "initSet = createInitSet(simpDat)\n",
    "myFPtree, myHeaderTab = createTree(initSet,3)\n",
    "myFPtree.disp()\n",
    "myFreqList = []\n",
    "mineTree(myFPtree, myHeaderTab, 3, set([]), myFreqList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "关联分析还有其他的算法，以后自己肯定还会进行更深入的学习，这两篇文章分别记录了**Apriori算法**和**FP growth算法**，这两个算法是很基础的，并且我们从FP growth算法对Apriori算法的改进中也应该体会这种优化的思维。这在自己建模以及使用经典模型中是很重要的。\n",
    "\n",
    "本系列笔记到这里也告一段落了，之后的学习还会继续补充**数据分析**和**机器学习**的内容，但估计不会每天更新。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
